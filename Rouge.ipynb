{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b144e6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE1:\n",
      "  Precision: 0.625\n",
      "  Recall:    0.625\n",
      "  F1 Score:  0.625\n",
      "\n",
      "ROUGE2:\n",
      "  Precision: 0.286\n",
      "  Recall:    0.286\n",
      "  F1 Score:  0.286\n",
      "\n",
      "ROUGEL:\n",
      "  Precision: 0.625\n",
      "  Recall:    0.625\n",
      "  F1 Score:  0.625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "reference = \"A panda eats bamboo leaves in the forest.\"\n",
    "generated = \"The panda is eating leaves in the jungle.\"\n",
    "\n",
    "# Create the scorer with more ROUGE variants\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "scores = scorer.score(reference, generated)\n",
    "\n",
    "# Print results\n",
    "for metric, score in scores.items():\n",
    "    print(f\"{metric.upper()}:\")\n",
    "    print(f\"  Precision: {score.precision:.3f}\")\n",
    "    print(f\"  Recall:    {score.recall:.3f}\")\n",
    "    print(f\"  F1 Score:  {score.fmeasure:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c671c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-S Score:\n",
      "{'precision': 0.222, 'recall': 0.214, 'f1': 0.218, 'num_overlap': 6, 'total_candidate': 27, 'total_reference': 28}\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations  # Import combinations to generate skip-bigrams (pairs of tokens)\n",
    "\n",
    "# Function to generate all skip-bigrams from a list of tokens\n",
    "def get_skip_bigrams(tokens):\n",
    "    return set(combinations(tokens, 2))  # Create all 2-token combinations where order matters\n",
    "\n",
    "# Function to compute ROUGE-S score\n",
    "def rouge_s(reference: str, candidate: str):\n",
    "    ref_tokens = reference.lower().split()      # Convert reference text to lowercase and split into words\n",
    "    cand_tokens = candidate.lower().split()     # Do the same for candidate text\n",
    "\n",
    "    ref_skip_bigrams = get_skip_bigrams(ref_tokens)     # Get all skip-bigrams from the reference\n",
    "    cand_skip_bigrams = get_skip_bigrams(cand_tokens)   # Get all skip-bigrams from the candidate\n",
    "\n",
    "    overlap = ref_skip_bigrams & cand_skip_bigrams      # Find common skip-bigrams using set intersection\n",
    "    num_overlap = len(overlap)                          # Count how many skip-bigrams overlap\n",
    "\n",
    "    # Calculate precision: overlapping / total skip-bigrams in candidate\n",
    "    precision = num_overlap / len(cand_skip_bigrams) if cand_skip_bigrams else 0\n",
    "\n",
    "    # Calculate recall: overlapping / total skip-bigrams in reference\n",
    "    recall = num_overlap / len(ref_skip_bigrams) if ref_skip_bigrams else 0\n",
    "\n",
    "    # Calculate F1-score using harmonic mean of precision and recall\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0\n",
    "\n",
    "    # Return results rounded to 3 decimal places along with debug info\n",
    "    return {\n",
    "        \"precision\": round(precision, 3),\n",
    "        \"recall\": round(recall, 3),\n",
    "        \"f1\": round(f1, 3),\n",
    "        \"num_overlap\": num_overlap,\n",
    "        \"total_candidate\": len(cand_skip_bigrams),\n",
    "        \"total_reference\": len(ref_skip_bigrams)\n",
    "    }\n",
    "\n",
    "# ----------- Test Example -----------\n",
    "\n",
    "reference = \"A panda eats bamboo leaves in the forest\"   # Reference summary\n",
    "generated = \"The panda is eating leaves in the jungle\"    # LLM-generated summary\n",
    "\n",
    "score = rouge_s(reference, generated)     # Run ROUGE-S calculation\n",
    "print(\"ROUGE-S Score:\")                   # Display label\n",
    "print(score)                              # Print the resulting precision, recall, f1, and overlap counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5720cbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/f6/d4/349f7f4bd5ea92dab34f5bb0fe31775ef6c311427a14d5a5b31ecb442341/absl_py-2.2.2-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nltk (from rouge-score)\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in d:\\langgraph-chapter1\\langgraphenv\\lib\\site-packages (from rouge-score) (2.2.3)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\langgraph-chapter1\\langgraphenv\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in d:\\langgraph-chapter1\\langgraphenv\\lib\\site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Collecting joblib (from nltk->rouge-score)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/da/d3/13ee227a148af1c693654932b8b0b02ed64af5e1f7406d56b088b57574cd/joblib-1.5.0-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk->rouge-score)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/80/32/763a6cc01d21fb3819227a1cc3f60fd251c13c37c27a73b8ff4315433a8e/regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk->rouge-score)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in d:\\langgraph-chapter1\\langgraphenv\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.6 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 92.2/135.6 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 135.6/135.6 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 0.9/1.5 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.9 MB/s eta 0:00:00\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   ---------------------------------------  307.2/307.7 kB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 307.7/307.7 kB 6.3 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (pyproject.toml): started\n",
      "  Building wheel for rouge-score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=25023 sha256=b31b5caf5f7d30a8663e0ad6d75ffa3877767ca196f95208bb26afcb1774578c\n",
      "  Stored in directory: c:\\users\\diwak\\appdata\\local\\pip\\cache\\wheels\\1e\\19\\43\\8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: tqdm, regex, joblib, absl-py, nltk, rouge-score\n",
      "Successfully installed absl-py-2.2.2 joblib-1.5.0 nltk-3.9.1 regex-2024.11.6 rouge-score-0.1.2 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df660b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraphenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
